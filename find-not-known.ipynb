{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "suffering-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vob_toefl_only_fp='toefl-only.txt'\n",
    "a_fp = 'article.txt'\n",
    "vob_cet6_fp = 'p_cet6.txt'\n",
    "vob_cet4_fp = 'p_cet4.txt'\n",
    "vob_except_fp = 'p_toefl_delete46.txt'\n",
    "\n",
    "vob_toefl_only=[]\n",
    "vob_toefl_only2 = []\n",
    "a=[]\n",
    "vob_cet6 = []\n",
    "vob_cet4 = []\n",
    "\n",
    "\n",
    "with open(vob_cet4_fp) as f:\n",
    "    vob_cet4 = f.readlines()\n",
    "with open(vob_cet6_fp) as f:\n",
    "    vob_cet6 = f.readlines()\n",
    "with open(vob_toefl_only_fp) as f:\n",
    "    vob_toefl_only = f.readlines()\n",
    "with open(vob_except_fp) as f:\n",
    "    vob_toefl_only2 = f.readlines()    \n",
    "\n",
    "with open(a_fp) as f:\n",
    "    a = f.readlines()    \n",
    "with open(a_fp) as f:\n",
    "    a_all = f.read()    \n",
    "a_all=a_all.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "killing-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "doc = nlp(a_all)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "realistic-sucking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noaa: global bleaching event threatens world\\'s coral reefs06:01\\n\\nplay\\noctober 08, 2015\\nalice lawrence, a marine biologist, assesses the bleaching at airport reef in american samoa in february 2015. (xl catlin seaview survey)\\nalice lawrence, a marine biologist, assesses the bleaching at airport reef in american samoa in february 2015. (xl catlin seaview survey)\\nthis article is more than 5 years old.\\nthe national oceanic and atmospheric administration (noaa) announced on thursday that the world\\'s coral reefs are in the middle of a dramatic bleaching event. that\\'s when stressful environmental conditions kill off huge swaths of coral, leaving it bone-white and unable to support marine life.\\n\\nit\\'s only the third time in history that we\\'ve seen such an event, and it\\'s potentially disastrous for the world\\'s oceans. mark eakin, a marine ecologist and coordinator of noaa\\'s coral reef watch program, talks with here & now\\'s jeremy hobson about the coral bleaching, and says climate change is the culprit.\\n\\nmost viewed stories\\n&quot;notes from the bathroom line: humor, art, and low-grade panic from 150 of the funniest women in comedy.\" (courtesy)\\n\\'notes from the bathroom line\\' collection showcases 150 women comedy writers\\nplay\\nhere & now11:04mar 18, 2021\\nthe serendipitous story of how a stray dog changed a former u.s. ambassador\\'s life\\nplay\\nhere & now09:35mar 15, 2021\\nvolunteers walk with chinatown seniors in oakland to combat anti-asian violence\\nplay\\nhere & now05:11feb 26, 2021\\npandemic life includes a lot of screen time for kids. is it time to cut back?\\nplay\\nhere & now09:42mar 18, 2021\\ninterview highlights\\nwhat is a coral bleaching event?\\n\\n“first i’ll explain what coral is because most people don’t realize they’re a plant, an animal and a mineral all at the same time. and that’s important because inside the tissues of this animal are microscopic algae that provide most of their food. when the water temp gets too high the photosynthesis - the production of energy by these little plant cells - actually starts to run too fast and they start to release toxins into the coral. as a method of survival the coral will eject the algae into the water and it leaves their tissues translucent so you can see right through to the skeleton underneath, which is white. so it looks like it’s bleached, it looks like it’s dead, the tissues are actually still alive but you have a sick coral that’s starving and more susceptible to disease.”\\n\\n\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "combined-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vob_toefl_only = pd.Series(vob_toefl_only).apply(lambda x:  x.replace('\\n',''))\n",
    "vob_toefl_only2 = pd.Series(vob_toefl_only2).apply(lambda x:  x.replace('\\n',''))\n",
    "vob_cet6 = pd.Series(vob_cet6).apply(lambda x:  x.replace('\\n',''))\n",
    "vob_cet4 = pd.Series(vob_cet4).apply(lambda x:  x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "quantitative-parish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#todo clean : remove es/s\n",
    "import string\n",
    "import nltk\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in string.punctuation]#+'\\n'\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct\n",
    "\n",
    "def tokenize(text):\n",
    "    split=re.split(\"\\W+\",text) \n",
    "    return split\n",
    "#remove stop\n",
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "tokens= remove_punctuation(a_all)\n",
    "tokens = tokenize(tokens)\n",
    "tokens= remove_stopwords(tokens)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-detroit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "adjustable-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noaa\n",
      "global\n",
      "bleaching\n",
      "event\n",
      "threatens\n",
      "worlds\n",
      "coral\n",
      "reefs0601\n",
      "play\n",
      "october\n",
      "08\n",
      "2015\n",
      "alice\n",
      "lawrence\n",
      "marine\n",
      "biologist\n",
      "assesses\n",
      "bleaching\n",
      "airport\n",
      "reef\n",
      "american\n",
      "samoa\n",
      "february\n",
      "2015\n",
      "xl\n",
      "catlin\n",
      "seaview\n",
      "survey\n",
      "alice\n",
      "lawrence\n",
      "marine\n",
      "biologist\n",
      "assesses\n",
      "bleaching\n",
      "airport\n",
      "reef\n",
      "american\n",
      "samoa\n",
      "february\n",
      "2015\n",
      "xl\n",
      "catlin\n",
      "seaview\n",
      "survey\n",
      "article\n",
      "5\n",
      "years\n",
      "old\n",
      "national\n",
      "oceanic\n",
      "atmospheric\n",
      "administration\n",
      "noaa\n",
      "announced\n",
      "thursday\n",
      "worlds\n",
      "coral\n",
      "reefs\n",
      "middle\n",
      "dramatic\n",
      "bleaching\n",
      "event\n",
      "thats\n",
      "stressful\n",
      "environmental\n",
      "conditions\n",
      "kill\n",
      "huge\n",
      "swaths\n",
      "coral\n",
      "leaving\n",
      "bonewhite\n",
      "unable\n",
      "support\n",
      "marine\n",
      "life\n",
      "third\n",
      "time\n",
      "history\n",
      "weve\n",
      "seen\n",
      "event\n",
      "potentially\n",
      "disastrous\n",
      "worlds\n",
      "oceans\n",
      "mark\n",
      "eakin\n",
      "marine\n",
      "ecologist\n",
      "coordinator\n",
      "noaas\n",
      "coral\n",
      "reef\n",
      "watch\n",
      "program\n",
      "talks\n",
      "nows\n",
      "jeremy\n",
      "hobson\n",
      "coral\n",
      "bleaching\n",
      "says\n",
      "climate\n",
      "change\n",
      "culprit\n",
      "viewed\n",
      "stories\n",
      "quotnotes\n",
      "bathroom\n",
      "line\n",
      "humor\n",
      "art\n",
      "lowgrade\n",
      "panic\n",
      "150\n",
      "funniest\n",
      "women\n",
      "comedy\n",
      "courtesy\n",
      "notes\n",
      "bathroom\n",
      "line\n",
      "collection\n",
      "showcases\n",
      "150\n",
      "women\n",
      "comedy\n",
      "writers\n",
      "play\n",
      "now1104mar\n",
      "18\n",
      "2021\n",
      "serendipitous\n",
      "story\n",
      "stray\n",
      "dog\n",
      "changed\n",
      "former\n",
      "us\n",
      "ambassadors\n",
      "life\n",
      "play\n",
      "now0935mar\n",
      "15\n",
      "2021\n",
      "volunteers\n",
      "walk\n",
      "chinatown\n",
      "seniors\n",
      "oakland\n",
      "combat\n",
      "antiasian\n",
      "violence\n",
      "play\n",
      "now0511feb\n",
      "26\n",
      "2021\n",
      "pandemic\n",
      "life\n",
      "includes\n",
      "lot\n",
      "screen\n",
      "time\n",
      "kids\n",
      "time\n",
      "cut\n",
      "back\n",
      "play\n",
      "now0942mar\n",
      "18\n",
      "2021\n",
      "interview\n",
      "highlights\n",
      "coral\n",
      "bleaching\n",
      "event\n",
      "first\n",
      "explain\n",
      "coral\n",
      "people\n",
      "realize\n",
      "plant\n",
      "animal\n",
      "mineral\n",
      "time\n",
      "important\n",
      "inside\n",
      "tissues\n",
      "animal\n",
      "microscopic\n",
      "algae\n",
      "provide\n",
      "food\n",
      "water\n",
      "temp\n",
      "gets\n",
      "high\n",
      "photosynthesis\n",
      "production\n",
      "energy\n",
      "little\n",
      "plant\n",
      "cells\n",
      "actually\n",
      "starts\n",
      "run\n",
      "fast\n",
      "start\n",
      "release\n",
      "toxins\n",
      "coral\n",
      "method\n",
      "survival\n",
      "coral\n",
      "eject\n",
      "algae\n",
      "water\n",
      "leaves\n",
      "tissues\n",
      "translucent\n",
      "see\n",
      "right\n",
      "skeleton\n",
      "underneath\n",
      "white\n",
      "looks\n",
      "like\n",
      "bleached\n",
      "looks\n",
      "like\n",
      "dead\n",
      "tissues\n",
      "actually\n",
      "still\n",
      "alive\n",
      "sick\n",
      "coral\n",
      "starving\n",
      "susceptible\n",
      "disease\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get reverse lemma\n",
    "doc_str = ''\n",
    "for i in tokens:\n",
    "    print(i)\n",
    "    doc_str=doc_str+ i + ' '\n",
    "        \n",
    "doc2=nlp(doc_str)\n",
    "doc2 = \" \".join([token.lemma_ for token in doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "american-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "def pltosig(word):\n",
    "    return p.singular_noun(word)\n",
    "    \n",
    "def clean(x):\n",
    "    result = re.findall('^[a-zA-Z]*', x )\n",
    "    if len(result)>0 :\n",
    "        if pltosig(result[0]):\n",
    "            return pltosig(result[0])\n",
    "        return result[0]\n",
    "    return \n",
    "doc3=re.split('\\W+', doc2) \n",
    "df = pd.Series(doc3).apply(lambda x: clean(x))\n",
    "#remove alphabet \n",
    "df=df.apply(lambda x: x if len(x)>1 else '' ) #a-z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-orlando",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "possible-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actually',\n",
       " 'administration',\n",
       " 'announce',\n",
       " 'article',\n",
       " 'biologist',\n",
       " 'cell',\n",
       " 'climate',\n",
       " 'condition',\n",
       " 'dramatic',\n",
       " 'ecologist',\n",
       " 'former',\n",
       " 'get',\n",
       " 'global',\n",
       " 'highlight',\n",
       " 'life',\n",
       " 'marine',\n",
       " 'microscopic',\n",
       " 'note',\n",
       " 'now',\n",
       " 'panic',\n",
       " 'reef',\n",
       " 'release',\n",
       " 'screen',\n",
       " 'sick',\n",
       " 'skeleton',\n",
       " 'starve',\n",
       " 'survey',\n",
       " 'survival',\n",
       " 'susceptible',\n",
       " 'threaten',\n",
       " 'tissue',\n",
       " 'translucent',\n",
       " 'underneath',\n",
       " 'violence',\n",
       " 'volunteer'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word in article intersection with konwn list (cet4 or cet6 or tofel)\n",
    "# list word in toefl\n",
    "set(df).intersection(set(vob_toefl_only) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "stainless-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'climate',\n",
       " 'combat',\n",
       " 'courtesy',\n",
       " 'disease',\n",
       " 'dramatic',\n",
       " 'eject',\n",
       " 'highlight',\n",
       " 'panic',\n",
       " 'release',\n",
       " 'skeleton',\n",
       " 'stray',\n",
       " 'survival',\n",
       " 'susceptible',\n",
       " 'threaten',\n",
       " 'tissue',\n",
       " 'volunteer'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list word in cet6\n",
    "set(df).intersection(set(vob_cet6) ) # word in article intersection with konwn list (cet4 or cet6 or tofel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "incomplete-choir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alga', 'reef', 'translucent'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list word in vob_toefl_only2\n",
    "set(df).intersection(set(vob_toefl_only2) ) # word in article intersection with konwn list (cet4 or cet6 or tofel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "damaged-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alga',\n",
       " 'alouse',\n",
       " 'ambassador',\n",
       " 'antiasian',\n",
       " 'asses',\n",
       " 'bleach',\n",
       " 'bleached',\n",
       " 'bleaching',\n",
       " 'bonewhite',\n",
       " 'catlin',\n",
       " 'chinatown',\n",
       " 'comedy',\n",
       " 'coordinator',\n",
       " 'coral',\n",
       " 'culprit',\n",
       " 'disastrou',\n",
       " 'eakin',\n",
       " 'environmental',\n",
       " 'february',\n",
       " 'funniest',\n",
       " 'hobson',\n",
       " 'humor',\n",
       " 'jeremy',\n",
       " 'lawrence',\n",
       " 'lowgrade',\n",
       " 'mineral',\n",
       " 'noaa',\n",
       " 'oakland',\n",
       " 'oceanic',\n",
       " 'october',\n",
       " 'pandemic',\n",
       " 'photosynthesi',\n",
       " 'potentially',\n",
       " 'quotnote',\n",
       " 'samoa',\n",
       " 'seaview',\n",
       " 'serendipitou',\n",
       " 'showcase',\n",
       " 'stressful',\n",
       " 'swath',\n",
       " 'temp',\n",
       " 'thursday',\n",
       " 'toxin',\n",
       " 've',\n",
       " 'xl'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df)- set(vob_toefl_only)  - set(vob_cet6)- set(vob_cet4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "preliminary-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(vob_toefl_only)  - set(vob_cet6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "subjective-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alouse',\n",
       " 'ambassador',\n",
       " 'antiasian',\n",
       " 'asses',\n",
       " 'biologist',\n",
       " 'bleach',\n",
       " 'bleached',\n",
       " 'bleaching',\n",
       " 'bonewhite',\n",
       " 'catlin',\n",
       " 'chinatown',\n",
       " 'comedy',\n",
       " 'coordinator',\n",
       " 'coral',\n",
       " 'culprit',\n",
       " 'disastrou',\n",
       " 'eakin',\n",
       " 'ecologist',\n",
       " 'environmental',\n",
       " 'february',\n",
       " 'funniest',\n",
       " 'global',\n",
       " 'hobson',\n",
       " 'humor',\n",
       " 'jeremy',\n",
       " 'lawrence',\n",
       " 'lowgrade',\n",
       " 'microscopic',\n",
       " 'mineral',\n",
       " 'noaa',\n",
       " 'oakland',\n",
       " 'oceanic',\n",
       " 'october',\n",
       " 'pandemic',\n",
       " 'photosynthesi',\n",
       " 'potentially',\n",
       " 'quotnote',\n",
       " 'samoa',\n",
       " 'seaview',\n",
       " 'serendipitou',\n",
       " 'showcase',\n",
       " 'stressful',\n",
       " 'swath',\n",
       " 'temp',\n",
       " 'thursday',\n",
       " 'toxin',\n",
       " 've',\n",
       " 'xl'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df)- set(vob_toefl_only2)  - set(vob_cet6) - set(vob_cet4) #- set(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "answering-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love you . it be easy'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO more case for stem\n",
    "# https://www.nltk.org/howto/stem.html\n",
    "abc='bleach bleached bleaching' #not work\n",
    "abc='loved apples' #work\n",
    "abc='loving you. it\\'s easy' #work\n",
    "abc2=nlp(abc)\n",
    "abc2 = \" \".join([token.lemma_ for token in abc2])\n",
    "abc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-glucose",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
